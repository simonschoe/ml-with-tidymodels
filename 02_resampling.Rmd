---
title: "02_resampling"
output: html_document
---

layout: false
class: middle, center, inverse

# 4.1 `rsample`:<br><br>General Resampling Infrastructure

---

background-image: url(https://www.tidymodels.org/images/rsample.png)
background-position: 95% 5%
background-size: 7.5%
layout: true

---

name: data-split

## 4.1 `rsample`: Resampling Infrastructure

`rsample` provides a set of methods for estimating the sampling distribution of a statistic (e.g., the test set error). A *resample* of the original data is viewed as the outcome of a resampling methode, e.g., a fold resulting from *k*-fold cross-validation or a bootstrapped sample resulting from sampling with replacement.
<br><br>

--

Resampling is generally applied subsequent to **data partitioning**, i.e. after the initial train-test-split. Note that the output of the `inital_split()` function does not contain the train and test data itself. It rather indexes the original data points according to their membership to the training respectively test set.
```{r}
set.seed(2020)
climbers_split <- initial_split(climbers_df, prop = 0.8, strata = died)

climbers_split
```

???
strata: conduct a stratified split -> keep proportions (i.e. imbalance) in training as well as in test set -> since sampling is random it might otherwise be that sampling creates an even severer or slighter imbalance

---

## 4.1 `rsample`: Resampling Infrastructure

To eventually extract the training and test data, we can use the `training()` and `testing()` functions. 
```{r, results='hide'}
train_set <- training(climbers_split)
test_set <- testing(climbers_split)

train_set
```
```{r, echo=F}
print(train_set, n = 5)
```

---

## 4.1 `rsample`: Resampling Infrastructure

Since we want to eventually implement classifiers that also contain hyperparameters we require a three-way split of our data:
- The *training set*, which is used for fitting the model
- The *validation set*, which is used for finding the optimal hyperparameter
- The *test set*, which is used for computing a robust estimate of the misclassification error

--

.pull-left[
Consequently, we need to further parition our initial `train_set` into a smaller training as well as a validation set using `initial_split()`.

```{r, echo=F, out.width='40%', out.height='40%', fig.align='center'}
knitr::include_graphics("https://www.tidymodels.org/start/case-study/img/validation-split.svg")
```
]

--

.pull-right[
 Or we refer to a resample approach, such as cross-validation (CV) or the bootstrap, to create resamples from our initial training set.
 
```{r, echo=F, out.width='70%', out.height='70%', fig.align='center'}
knitr::include_graphics("https://www.tidymodels.org/start/resampling/img/resampling.svg")
```
]

???
- we usually prefer the latter as we would like to generate a distribution of our error measure and to account for uncertainty in the estimate
- i prefer the terms training and validation instead of analysis and assessment set in the context of resampling

---

## 4.1 `rsample`: Resampling Infrastructure

In this case study, we implement a **10-fold CV** approach using the `vfold_cv()` function. It returns a `tibble` containing the indexes of 10 separate splits.

```{r}
set.seed(2020)
climbers_folds <- train_set %>% 
  vfold_cv(v = 10, repeats = 1, strata = died) 

climbers_folds
```

.footnote[.pull-right[
*Note: Alternatively, use `bootstraps()` to draw bootstrap samples with replacement. Observations not included in the bootstrap samples constitute the validation set ("out-of-bag" observations).*
]]

---

## 4.1 `rsample`: Resampling Infrastructure

To extract the training and validation data from each fold, we can use the `anaylsis()` and `assessment()` functions. 
```{r, eval=F}
climbers_folds %>%
  pluck("splits", 1) %>%
  analysis()
```
```{r, eval=F}
climbers_folds %>%
  pluck("splits", 1) %>%
  assessment()
```
Note that `rsample` discriminates between train and test as well as analysis and assessment sets:
- use `training()` and `testing()` to extract data after partitioning
- use `analysis()` and `assessment()` to extract data after resampling

.footnote[
<i>Note: For data with a strong time-series component (i.e. temporally ordered data), `rsample` also provides appropriate resampling infrastructure. For example, you may use `initial_time_split()` to produce a non-random temporal train-test-split and `rolling_origin()` or the `slide_*()` methods to generate time-series resamples.</i>
]
